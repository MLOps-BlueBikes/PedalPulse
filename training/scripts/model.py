
from datetime import datetime
import logging
import os
import sys
import mlflow 
from mlflow.exceptions import RestException
import joblib
from google.cloud import storage
import pandas as pd
import gcsfs
from sklearn.linear_model import LinearRegression
from load_data import load_data_from_gcs
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
import time
from app.config import GCP_BUCKET_NAME, GCP_DATA_FILE, MODEL_SAVE_PATH, LOG_PATH
from google.cloud import storage
# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(message)s")
logger = logging.getLogger()
dt_model_path = os.path.join(MODEL_SAVE_PATH, "decision_tree_model.pkl")
lr_model_path = os.path.join(MODEL_SAVE_PATH, "linear_regression_model.pkl")
mlflow.set_tracking_uri("http://34.55.73.138:5050")
mlflow.set_experiment("PedalPulse")
mlflow_client=mlflow.MlflowClient(tracking_uri="http://34.55.73.138:5050")


# GCS and Environment Configurations
BUCKET_NAME = os.getenv("BUCKET_NAME", "skc-pedalpulse-testing")
MODEL_DIR = os.getenv("MODEL_DIR", f"gs://{BUCKET_NAME}/models/model/")
LOG_DIR = os.getenv("LOG_DIR", f"gs://{BUCKET_NAME}/logs/")

fs = gcsfs.GCSFileSystem(project='pedalpulse-skc')
storage_client = storage.Client()


# Upload logs to GCS
def upload_log_to_gcs(log_content, log_path):
    try:
        with fs.open(log_path, 'wb') as log_file:
            log_file.write(log_content.encode())
        logger.info(f"Logs uploaded to {log_path}")
    except Exception as e:
        logger.error(f"Failed to upload logs: {e}")
        raise


def preprocess_data(df):
    """
    Preprocess the data:
    - Resample the data hourly by start_station_name.
    - Encode categorical variables.
    - Scale numerical features.

    Args:
    df (pandas.DataFrame): Raw input DataFrame.

    Returns:
    tuple: Preprocessed features (X), target (y), and the preprocessor pipeline.
    """
    try:
        df['started_at'] = pd.to_datetime(df['started_at'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

        # Drop rows where 'started_at' is NaT
        df = df.dropna(subset=['started_at'])
        
        # Set the datetime column as the index for resampling
        df.set_index('started_at', inplace=True)
        logger.info("Data preprocessed. Starting resampling...")

        # Resample data by hour for each station
        hourly_station_data = df.groupby('start_station_name').resample('h').agg({
            'month': 'first',                # Keep first value (since it's constant for each hour)
            'hour': 'first',                 # Same as above
            'day_name': 'first',             # Same
            'duration': 'sum',               # Sum durations for the hour
            'distance_km': 'sum',            # Sum distances for the hour
            'Temperature (Â°F)': 'mean',      # Average temperature
            'Humidity': 'mean',              # Average humidity
            'Wind Speed': 'mean',            # Average wind speed
            'Precip.': 'sum',                # Total precipitation for the hour
            'Condition': 'first',            # Keep first condition as representative
            'BikeUndocked': 'sum'            # Sum undocked bikes
        }).reset_index()

        logging.info("Data resampling completed.")
        # Prepare features (X) and target (y)
        X = hourly_station_data.drop(columns=['BikeUndocked'])
        y = hourly_station_data['BikeUndocked']

        # One-hot encode categorical variables
        logger.info("Applying one-hot encoding...")
        X = pd.get_dummies(X, columns=['day_name', 'Condition'], drop_first=True)

        # Frequency encode the 'start_station_name' column
        logger.info("Applying frequency encoding to 'start_station_name'...")
        station_freq = X['start_station_name'].value_counts().to_dict()
        X['start_station_name'] = X['start_station_name'].map(station_freq).fillna(0)

        # Drop unnecessary columns
        logger.info("Dropping unnecessary columns...")
        X = X.drop(columns=['started_at'])

        # Fill any remaining missing values with 0
        X = X.fillna(0)

        logger.info(f"Final feature columns: {X.columns}")

        # Split the data chronologically into train, validation, and test sets
        train_size = int(0.7 * len(X))  # 70% for training
        val_size = int(0.15 * len(X))   # 15% for validation
        test_size = len(X) - train_size - val_size  # 15% for test

        X_train, y_train = X[:train_size], y[:train_size]
        X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]
        X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]

        logger.info("Data splitting into train, validation, and test sets completed.")
        # Upload log after preprocessing
        upload_log_to_gcs("Data preprocessing and resampling completed.", LOG_DIR + "/preprocessing_log.txt")

        return X_train, X_val, X_test, y_train, y_val, y_test

    except Exception as e:
        logging.error(f"Error in preprocessing: {e}")
        raise
# Train the model
def train_model(X_train, y_train, X_val, y_val,X_test,y_test):
    date=datetime.today()
    try:
      with mlflow.start_run(run_name=f'run_{date}'):
        mlflow.log_param('dataset_version',date.strftime("%m-%Y"))
        mlflow.log_param("train_size", '0.7')
        mlflow.log_param("val_size",'0.15')
        # # # Linear Regression
        with mlflow.start_run(run_name="Linear Regression with GridSearch",nested=True):
            

            pipe_lr = Pipeline([('scl', StandardScaler()), ('reg', LinearRegression())])
            logger.info("Pipeline created")
            param_grid_lr = {'reg__fit_intercept': [True, False], 'reg__positive': [True, False]}
            grid_search_lr = GridSearchCV(pipe_lr, param_grid=param_grid_lr, cv=5)
            logger.info("Starting GridSearchCV for Linear Regression...")
            grid_search_lr.fit(X_train, y_train)

            y_pred = grid_search_lr.predict(X_val)
            lr_val_mse = mean_squared_error(y_val, y_pred)
            lr_val_r2 = r2_score(y_val, y_pred)

            y_pred = grid_search_lr.predict(X_test)
            lr_test_mse = mean_squared_error(y_test, y_pred)
            lr_test_r2 = r2_score(y_test, y_pred)

            logger.info(f"Validation MSE: {lr_val_mse}, R2: {lr_val_r2}")
            logger.info(f"Test MSE: {lr_test_mse}, R2: {lr_test_r2}")


            # Log metrics and parameters with MLflow
            mlflow.log_params(grid_search_lr.best_params_)
            mlflow.log_metric("test_mean_squared_error", lr_test_mse)
            mlflow.log_metric("test_r2_score", lr_test_r2)
            mlflow.log_metric("val_mean_squared_error", lr_val_mse)
            mlflow.log_metric("val_r2_score", lr_val_r2)

            logger.info("Attempting to save models...")
            #mlflow.sklearn.log_model(grid_lr.best_estimator_, "linear_regression_model")

            #joblib.dump(grid_lr.best_estimator_, "models/model.pkl")
            joblib.dump(grid_search_lr.best_estimator_, lr_model_path)
            # Save model to path specified in config
        ### Decision Tree
        with mlflow.start_run(run_name="Decision Tree Regressor with GridSearch",nested=True):
            # Define and train a Decision Tree Regressor
            model = DecisionTreeRegressor(random_state=42)
            param_grid = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5]}
            grid_search_dt = GridSearchCV(model, param_grid, cv=5)
            
            logger.info("Starting GridSearchCV for Decision Tree...")            
            grid_search_dt.fit(X_train, y_train)

            # Evaluate the model
            y_pred = grid_search_dt.predict(X_val)
            dt_val_mse = mean_squared_error(y_val, y_pred)
            dt_val_r2 = r2_score(y_val, y_pred)

            y_pred = grid_search_dt.predict(X_test)
            dt_test_mse = mean_squared_error(y_test, y_pred)
            dt_test_r2 = r2_score(y_test, y_pred)

            mlflow.log_params(grid_search_dt.best_params_)
            mlflow.log_metric("test_mean_squared_error", dt_test_mse)
            mlflow.log_metric("test_r2_score", dt_test_r2)
            mlflow.log_metric("val_mean_squared_error", dt_val_mse)
            mlflow.log_metric("val_r2_score", dt_val_r2)
            
            joblib.dump(grid_search_dt.best_estimator_, dt_model_path)
            logger.info(f"Validation MSE: {dt_val_mse}, R2: {dt_val_r2}")
            logger.info(f"Test MSE: {dt_test_mse}, R2: {dt_test_r2}")

        bm=pick_best_model(test_x= X_test,test_y= y_test)
        best_model= joblib.load(lr_model_path if bm=='lr' else dt_model_path)
        best_model_r2= lr_val_r2 if bm=='lr' else dt_val_r2
        best_model_mse= lr_val_mse if bm=='lr' else dt_val_mse

            
        # Upload log after training
        #upload_log_to_gcs(f"Training completed. Validation MSE: {mse}, R2: {r2}.", LOG_DIR + "/training_log.txt")
        print(f"Selected {bm}")
        try:
               latest_model_version = mlflow_client.get_latest_versions('pedalpulse_demand_prediction_model')
            
        except RestException as e:
                mlflow.sklearn.log_model(sk_model=best_model,artifact_path='pedalpulse_models',registered_model_name='pedalpulse_demand_prediction_model')
                return best_model
               
        if latest_model_version:
                lm=latest_model_version[0]
                print(f"Latest model is {lm._name}-{lm._version} ")
                lm_run_metrics= mlflow_client.get_run(run_id=lm.run_id).data.metrics

                print(f'Latest model performance : {lm_run_metrics} Current trained best model performance: mse={best_model_mse}, r2={best_model_r2}')
                if best_model_r2 > lm_run_metrics['r2']:
                    print("The newly trained model is performing better than latest model!!!, registering it")
                    mlflow.sklearn.log_model(sk_model=best_model,artifact_path='pedalpulse_models',registered_model_name='pedalpulse_demand_prediction_model')
                    return best_model
                else:
                    return None 
        else:
            return None
            
    except Exception as e:
        logger.error(f"Error in training: {e}")
        raise

def pick_best_model(test_x,test_y):

    df=pd.concat([test_x,test_y],axis=1)


    lr_model=joblib.load(lr_model_path)
    dt_model=joblib.load(dt_model_path)

    lr_r2=r2_score(lr_model.predict(test_x),test_y)
    dt_r2=r2_score(dt_model.predict(test_x),test_y)

    station_freq = df['start_station_name'].value_counts()
    # Get the most and least frequent stations
    most_frequent_stations = station_freq.head(10).index
    least_frequent_stations = station_freq.tail(10).index

    # Filter data for most and least frequent stations
    most_freq_data = df[df['start_station_name'].isin(most_frequent_stations)]
    least_freq_data = df[df['start_station_name'].isin(least_frequent_stations)]

    lr_r2_most_freq=r2_score(lr_model.predict(most_freq_data.drop(['BikeUndocked'],axis=1)),most_freq_data['BikeUndocked'])
    lr_r2_least_freq=r2_score(lr_model.predict(least_freq_data.drop(['BikeUndocked'],axis=1)),least_freq_data['BikeUndocked'])
    logger.info(f"Linear Regression R2 score for top 10 most frequent stations:{lr_r2_most_freq} least frequent stations: {lr_r2_least_freq}")
    dt_r2_most_freq=r2_score(dt_model.predict(most_freq_data.drop(['BikeUndocked'],axis=1)),most_freq_data['BikeUndocked'])
    dt_r2_least_freq=r2_score(dt_model.predict(least_freq_data.drop(['BikeUndocked'],axis=1)),least_freq_data['BikeUndocked'])
    logger.info(f"Decision Tree Regression R2 score for top 10 most frequent stations:{dt_r2_most_freq} least frequent stations: {dt_r2_least_freq}")

    if abs(lr_r2_most_freq-lr_r2_least_freq) < abs(dt_r2_most_freq-dt_r2_least_freq):
        return "lr"
    elif dt_r2>lr_r2:
        return "dt"
    else:
        return "lr"
    

    
    






    
    








def upload_to_gcs(local_path, bucket_name, destination_blob_name):
    """Uploads a file to Google Cloud Storage."""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)
    blob.upload_from_filename(local_path)
    print(f"Uploaded {local_path} to gs://{bucket_name}/{destination_blob_name}")


# Main pipeline
def main():
    try:
        # Load data
        df = load_data_from_gcs(GCP_BUCKET_NAME, GCP_DATA_FILE)
        #data_cleaned = load_data_from_gcs(GCP_BUCKET_NAME, GCP_DATA_FILE)

        # Preprocess data
        X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(df)

        # Train the model
        model = train_model(X_train, y_train, X_val, y_val,X_test,y_test)
        
        if model:
            # Save artifacts
            model_path = os.path.join(MODEL_DIR, "model.pkl")
            
            # Example usage in training script:
            joblib.dump(model, dt_model_path)
            local_model_path = "./models/decision_tree_model.pkl"
        
            gcs_model_path = f"models/model/model.pkl"

            upload_to_gcs(local_model_path, GCP_BUCKET_NAME, gcs_model_path)
            sys.exit(0)
        else:
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
